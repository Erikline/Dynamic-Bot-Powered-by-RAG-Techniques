# å¯¼å…¥æ‰€éœ€çš„åº“
import os
import json
import re
import tempfile
import streamlit as st
from PIL import Image
import logging
import warnings
from dotenv import load_dotenv
import torch 
import shutil 
import hashlib 

# åŠ è½½ç¯å¢ƒå˜é‡ (ç¡®ä¿ .env æ–‡ä»¶å­˜åœ¨æˆ–ç¯å¢ƒå˜é‡å·²è®¾ç½®)
load_dotenv()

# å¿½ç•¥ç‰¹å®šçš„ Streamlit å¼ƒç”¨è­¦å‘Š
warnings.filterwarnings(
    "ignore",
    category=DeprecationWarning,
    message=".*use_column_width parameter has been deprecated.*"
)

# å¯¼å…¥ Langchain ç›¸å…³æ¨¡å—
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_huggingface import HuggingFaceEmbeddings # Embeddings ä¿æŒä¸å˜
from langchain.callbacks.base import BaseCallbackHandler
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document

# å¯¼å…¥ DashScope (OpenAIå…¼å®¹æ¨¡å¼) æ‰€éœ€çš„ç»„ä»¶
try:
    from langchain_openai import ChatOpenAI # <--- ä½¿ç”¨ LangChain çš„ OpenAI åŒ…è£…å™¨
except ImportError:
    st.error("æ‰¾ä¸åˆ° langchain-openai åº“ã€‚è¯·å®‰è£…å®ƒï¼špip install -U langchain-openai")
    st.stop()
try:
    import openai # æ£€æŸ¥ openai åº“æœ¬èº«æ˜¯å¦å­˜åœ¨
except ImportError:
    st.error("æ‰¾ä¸åˆ° openai åº“ã€‚è¯·å®‰è£…å®ƒï¼špip install -U openai")
    st.stop()


# --- é…ç½® ---
# DashScope (ç™¾ç‚¼) API é…ç½®
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY") # ä»ç¯å¢ƒå˜é‡è·å–
DASHSCOPE_API_BASE = "https://dashscope.aliyuncs.com/compatible-mode/v1"

if not DASHSCOPE_API_KEY:
    st.error("æœªæ‰¾åˆ° DashScope API å¯†é’¥ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY æˆ–åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ã€‚")
    st.info("å¦‚ä½•è·å–API Key: https://help.aliyun.com/zh/model-studio/developer-reference/get-api-key")
    st.stop()

# --- æ¨¡å‹é…ç½® ---
MODEL_ID = "deepseek-r1" # ä½¿ç”¨ DashScope çš„æ¨¡å‹åç§°

# --- æŒä¹…åŒ–é…ç½® ---
PERSIST_DIRECTORY = r"D:\Desktop\xxxxxx\chroma_db_streamlit" # <--- ChromaDB æ•°æ®å°†ä¿å­˜åˆ°è¿™ä¸ªç›®å½•
PERSIST_STATE_FILE = os.path.join(PERSIST_DIRECTORY, "processed_files_state.json") # <--- ç”¨äºè®°å½•æ–‡ä»¶çŠ¶æ€çš„jsonæ–‡ä»¶

# --- åº”ç”¨è®¾ç½® ---
APP_TITLE = f"ä½¿ç”¨ {MODEL_ID} å’Œ åŸºäº BGE è¯åµŒå…¥ çš„ ChromaDB çš„ RAG åº”ç”¨ (æ”¯æŒæŒä¹…åŒ–ä¸æ–‡ä»¶åŒæ­¥)"
FAVICON_PATH = r"D:\Desktop\xxxxxx\Bot.png" # è¯·æ›¿æ¢ä¸ºä½ çš„å®é™…è·¯å¾„
LOGO_PATH = r"D:\Desktop\ç¨‹åº\03-æ„å»ºåŠ¨æ€LLM-Botæ¨¡å‹ä»£ç \icon.png"   # è¯·æ›¿æ¢ä¸ºä½ çš„å®é™…è·¯å¾„

try:
    favicon = Image.open(FAVICON_PATH)
    st.set_page_config(page_title=APP_TITLE, page_icon=favicon, layout="wide")
except FileNotFoundError:
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.warning(f"åœ¨è·¯å¾„ {FAVICON_PATH} æœªæ‰¾åˆ° Favicon å›¾æ ‡ã€‚è·³è¿‡é¡µé¢å›¾æ ‡è®¾ç½®ã€‚")
except Exception as e:
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.warning(f"æ— æ³•åŠ è½½ Favicon å›¾æ ‡: {e}")

# --- Streamlit ä¾§è¾¹æ  ---
try:
    st.sidebar.image(LOGO_PATH, use_container_width=True)
except FileNotFoundError:
    st.sidebar.warning(f"åœ¨è·¯å¾„ {LOGO_PATH} æœªæ‰¾åˆ° Logo å›¾ç‰‡ã€‚")
except Exception as e:
     st.sidebar.warning(f"æ— æ³•åŠ è½½ Logo å›¾ç‰‡: {e}")

with st.sidebar:
    st.markdown(f"**{APP_TITLE}**")
    # æ·»åŠ ä¸€ä¸ªæŒ‰é’®ç”¨äºæ¸…é™¤ç¼“å­˜å’ŒæŒä¹…åŒ–æ•°æ®ï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒè¯•æˆ–å¤„ç†ä¸åŒæ–‡ä»¶ï¼‰
    if st.button("æ¸…é™¤æ‰€æœ‰æ•°æ®ç¼“å­˜ (åŒ…æ‹¬ ChromaDB)", key="clear_cache_and_db"):
         st.cache_resource.clear() # æ¸…é™¤ Streamlit çš„èµ„æºç¼“å­˜
         if os.path.exists(PERSIST_DIRECTORY):
             st.info(f"æ­£åœ¨æ¸…ç†æ—§çš„ Chroma ç›®å½•: {PERSIST_DIRECTORY}")
             try:
                 shutil.rmtree(PERSIST_DIRECTORY) # æ¸…é™¤æŒä¹…åŒ–ç›®å½•
                 st.sidebar.success("å·²æ¸…é™¤ç¼“å­˜å’Œ ChromaDB æŒä¹…åŒ–æ•°æ®ã€‚è¯·åˆ·æ–°é¡µé¢å¹¶é‡æ–°ä¸Šä¼ æ–‡ä»¶ã€‚")
                 st.rerun() # é‡æ–°è¿è¡Œåº”ç”¨
             except Exception as e:
                 st.sidebar.error(f"æ¸…é™¤ ChromaDB ç›®å½•å¤±è´¥: {e}")
                 logging.error(f"æ¸…é™¤ ChromaDB ç›®å½•å¤±è´¥: {e}", exc_info=True)
         else:
             st.sidebar.info("æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ¸…é™¤çš„ ChromaDB æŒä¹…åŒ–æ•°æ®ã€‚")


# --- æ–‡ä»¶å¤„ç†è¾…åŠ©å‡½æ•° ---
def calculate_file_hash(uploaded_file):
    """è®¡ç®—ä¸Šä¼ æ–‡ä»¶çš„ SHA256 å“ˆå¸Œå€¼ã€‚"""
    sha256 = hashlib.sha256()
    # Rewind the file pointer to the beginning
    uploaded_file.seek(0)
    # Read the file in chunks to handle large files
    while True:
        data = uploaded_file.read(8192) # Read in 8KB chunks
        if not data:
            break
        sha256.update(data)
    # Reset file pointer again for subsequent reads (e.g., by loader)
    uploaded_file.seek(0)
    return sha256.hexdigest()

def load_processed_state():
    """ä»çŠ¶æ€æ–‡ä»¶åŠ è½½ä¹‹å‰å¤„ç†çš„æ–‡ä»¶çŠ¶æ€ï¼ˆæ–‡ä»¶åå’Œå“ˆå¸Œå€¼ï¼‰ã€‚"""
    if os.path.exists(PERSIST_STATE_FILE):
        try:
            with open(PERSIST_STATE_FILE, 'r') as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"åŠ è½½æ–‡ä»¶çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
            return {} # åŠ è½½å¤±è´¥åˆ™è¿”å›ç©ºå­—å…¸
    return {}

def save_processed_state(state_dict):
    """å°†å½“å‰æ–‡ä»¶çŠ¶æ€ï¼ˆæ–‡ä»¶åå’Œå“ˆå¸Œå€¼ï¼‰ä¿å­˜åˆ°çŠ¶æ€æ–‡ä»¶ã€‚"""
    os.makedirs(PERSIST_DIRECTORY, exist_ok=True)
    try:
        with open(PERSIST_STATE_FILE, 'w') as f:
            json.dump(state_dict, f, indent=4)
    except Exception as e:
        logging.error(f"ä¿å­˜æ–‡ä»¶çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)


# --- æ ¸å¿ƒ RAG åŠŸèƒ½ (configure_retriever - åº”ç”¨ GPU ä¿®æ­£ & æŒä¹…åŒ– & æ–‡ä»¶åŒæ­¥) ---
@st.cache_resource(ttl="2h") # ç¼“å­˜2å°æ—¶
# ä¿®æ”¹å‡½æ•°ç­¾åå’Œè¿”å›å€¼ï¼Œè¿”å› (retriever, boolean_was_loaded)
def configure_retriever(uploaded_files):
    """
    åŸºäºä¸Šä¼ çš„æ–‡ä»¶æˆ–ç°æœ‰çš„æŒä¹…åŒ–æ•°æ®é…ç½®å¹¶è¿”å›ä¸€ä¸ª ChromaDB æ£€ç´¢å™¨ã€‚
    è¿”å›ä¸€ä¸ªå…ƒç»„ï¼š(æ£€ç´¢å™¨å¯¹è±¡, æ˜¯å¦ä»ç£ç›˜åŠ è½½çš„å¸ƒå°”å€¼)
    å¤„ç†æ–‡ä»¶å˜æ›´é€»è¾‘ã€‚
    """
    temp_dir = None
    chroma_retriever = None
    was_loaded_from_disk = False # æ–°å¢æ ‡å¿—

    # 1. åˆ›å»º Embedding æ¨¡å‹ (åŠ è½½å’Œåˆ›å»ºéƒ½éœ€è¦)
    try:
        st.info("æ­£åœ¨åˆå§‹åŒ– BGE åµŒå…¥æ¨¡å‹ (ç”¨äº Chroma)...")
        # æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨ï¼Œå¦‚æœå¯ç”¨åˆ™ä½¿ç”¨ GPUï¼Œå¦åˆ™å›é€€åˆ° CPU
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        st.info(f"æ£€æµ‹åˆ°å¯ç”¨è®¾å¤‡: {device}ï¼Œå°†ç”¨äºåµŒå…¥æ¨¡å‹åŠ è½½ã€‚")
        if device == 'cuda':
             # å°è¯•è·å– GPU å‹å·ï¼Œå¦‚æœå¤±è´¥åˆ™å¿½ç•¥
             try:
                st.info(f"GPU å‹å·: {torch.cuda.get_device_name(0)}")
             except Exception:
                st.warning("æ— æ³•è·å– GPU å‹å·ä¿¡æ¯ã€‚")

        # å®šä¹‰æ¨¡å‹åŠ è½½å‚æ•°ï¼Œæ˜ç¡®æŒ‡å®šè®¾å¤‡
        model_kwargs = {'device': device}
        # BGE æ¨¡å‹æ¨èå¯¹åµŒå…¥è¿›è¡Œå½’ä¸€åŒ–
        encode_kwargs = {'normalize_embeddings': True}

        embeddings = HuggingFaceEmbeddings(
            model_name="BAAI/bge-large-zh-v1.5", # ç¡®ä¿æ¨¡å‹åç§°æ­£ç¡®
            model_kwargs=model_kwargs,
            encode_kwargs=encode_kwargs
        )
        st.success("BGE åµŒå…¥æ¨¡å‹åˆå§‹åŒ–æˆåŠŸã€‚")

    except Exception as e:
        st.error(f"åˆå§‹åŒ– BGE åµŒå…¥æ¨¡å‹å¤±è´¥: {e}")
        logging.error("Embedding åˆå§‹åŒ–å¤±è´¥:", exc_info=True)
        if "out of memory" in str(e).lower():
            st.error("GPU æ˜¾å­˜ä¸è¶³ï¼è¯·å°è¯•å…³é—­å…¶ä»–å ç”¨æ˜¾å­˜çš„ç¨‹åºï¼Œæˆ–åœ¨ä»£ç ä¸­å°† device æ”¹ä¸º 'cpu'ã€‚")
        elif "meta tensor" in str(e):
            st.error("åŠ è½½æ¨¡å‹æ—¶é‡åˆ° Meta Tensor é”™è¯¯ã€‚è¯·å°è¯•æ¸…ç† Hugging Face æ¨¡å‹ç¼“å­˜ï¼ˆé€šå¸¸åœ¨ ~/.cache/huggingface/hub æˆ– C:\\Users\\<ç”¨æˆ·>\\.cache\\huggingface\\hubï¼‰ï¼Œç„¶åé‡å¯åº”ç”¨ã€‚å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·æ£€æŸ¥ PyTorch å’Œ transformers åº“ç‰ˆæœ¬ã€‚")
        else:
             st.error("è¯·æ£€æŸ¥æ¨¡å‹åç§°ã€ç½‘ç»œè¿æ¥æˆ–ç³»ç»Ÿèµ„æºã€‚")
        return None, False # Embedding æ¨¡å‹å¤±è´¥ï¼Œæ— æ³•ç»§ç»­ï¼Œè¿”å›Noneå’ŒFalse

    # 2. æ£€æŸ¥æ–‡ä»¶çŠ¶æ€å¹¶å†³å®šåŠ è½½æˆ–é‡å»º
    current_files_state = {}
    if uploaded_files:
        st.info("æ­£åœ¨è®¡ç®—ä¸Šä¼ æ–‡ä»¶çš„å“ˆå¸Œå€¼ä»¥æ£€æŸ¥æ˜¯å¦æœ‰å˜æ›´...")
        try:
            # è®¡ç®—å½“å‰ä¸Šä¼ æ–‡ä»¶çš„çŠ¶æ€ (æ–‡ä»¶å: å“ˆå¸Œå€¼)
            for file in uploaded_files:
                current_files_state[file.name] = calculate_file_hash(file)
            st.success(f"å·²è®¡ç®— {len(uploaded_files)} ä¸ªæ–‡ä»¶çš„å“ˆå¸Œå€¼ã€‚")
        except Exception as e:
            st.error(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼å¤±è´¥: {e}")
            logging.error("è®¡ç®—å“ˆå¸Œå¤±è´¥:", exc_info=True)
            # å¦‚æœè®¡ç®—å“ˆå¸Œå¤±è´¥ï¼Œæ— æ³•å®‰å…¨åœ°åˆ¤æ–­æ–‡ä»¶æ˜¯å¦å˜æ›´ï¼Œæ­¤æ—¶ç¨³å¦¥èµ·è§å¼ºåˆ¶é‡å»º
            st.warning("æ–‡ä»¶å“ˆå¸Œè®¡ç®—å¤±è´¥ï¼Œä¸ºç¡®ä¿æ•°æ®å‡†ç¡®æ€§ï¼Œå°†å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ–‡ä»¶ã€‚")
            current_files_state = {} # ç½®ç©ºï¼Œç¡®ä¿ä¸åŒ¹é…æ—§çŠ¶æ€ï¼Œå¼ºåˆ¶é‡å»º
            uploaded_files = [] # æ¸…ç©ºuploaded_filesåˆ—è¡¨ï¼Œä»¥ä¾¿ä¸‹ä¸€æ­¥èµ°é‡å»ºæµç¨‹

    # åŠ è½½ä¹‹å‰ä¿å­˜çš„æ–‡ä»¶çŠ¶æ€
    previous_files_state = load_processed_state()

    # åˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°æ„å»ºå‘é‡æ•°æ®åº“
    # éœ€è¦é‡å»ºçš„æƒ…å†µï¼š
    # 1. æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶ (uploaded_files ä¸ºç©º)ï¼Œä½†ä¹‹å‰ä¿å­˜çš„çŠ¶æ€ä¸ä¸ºç©ºï¼ˆè¯´æ˜ç”¨æˆ·è¿™æ¬¡æ²¡ä¼ æ–‡ä»¶ï¼Œä½†ä¸Šæ¬¡å¤„ç†è¿‡ï¼‰ -> å°è¯•åŠ è½½æ—§æ•°æ®
    # 2. ä¸Šä¼ äº†æ–‡ä»¶ (uploaded_files éç©º)ï¼Œä½†ä¹‹å‰æ²¡æœ‰ä¿å­˜çš„çŠ¶æ€æ–‡ä»¶ æˆ–è€… å½“å‰æ–‡ä»¶çŠ¶æ€ä¸ä¹‹å‰ä¿å­˜çš„çŠ¶æ€ä¸ä¸€è‡´ -> é‡å»º
    needs_rebuild = False
    if uploaded_files: # å¦‚æœç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶
        if not previous_files_state:
            st.info("æœªæ‰¾åˆ°ä¹‹å‰çš„æ–‡æ¡£æ•°æ®çŠ¶æ€ï¼Œå°†æ ¹æ®å½“å‰ä¸Šä¼ æ–‡ä»¶åˆ›å»ºæ–°çš„å‘é‡å­˜å‚¨ã€‚")
            needs_rebuild = True
        elif current_files_state != previous_files_state:
            st.info("æ£€æµ‹åˆ°ä¸Šä¼ æ–‡ä»¶ä¸ä¹‹å‰ä¿å­˜çš„æ•°æ®çŠ¶æ€ä¸ä¸€è‡´ (æ–‡ä»¶æ•°é‡ã€åç§°æˆ–å†…å®¹æœ‰å˜æ›´)ï¼Œå°†é‡æ–°åˆ›å»ºå‘é‡å­˜å‚¨ã€‚")
            # è¯¦ç»†è¯´æ˜å“ªäº›æ–‡ä»¶å˜äº†ï¼ˆå¯é€‰ï¼‰
            changed_files = [name for name, hash_val in current_files_state.items() if name not in previous_files_state or previous_files_state.get(name) != hash_val]
            removed_files_from_upload = [name for name in previous_files_state if name not in current_files_state]
            if changed_files: st.info(f"å˜åŠ¨æˆ–æ–°å¢æ–‡ä»¶: {', '.join(changed_files)}")
            if removed_files_from_upload: st.info(f"æœ¬æ¬¡æœªä¸Šä¼ ä½†ä¸Šæ¬¡å¤„ç†è¿‡çš„æ–‡ä»¶: {', '.join(removed_files_from_upload)}")

            needs_rebuild = True
        else:
            st.info("ä¸Šä¼ æ–‡ä»¶ä¸ä¹‹å‰ä¿å­˜çš„æ•°æ®çŠ¶æ€ä¸€è‡´ï¼Œå°†å°è¯•åŠ è½½ç°æœ‰çš„å‘é‡å­˜å‚¨ã€‚")
            needs_rebuild = False # çŠ¶æ€ä¸€è‡´ï¼Œä¸éœ€è¦é‡å»º
    elif previous_files_state: # å¦‚æœæ²¡æœ‰ä¸Šä¼ æ–‡ä»¶ï¼Œä½†æœ‰æ—§çŠ¶æ€ï¼ˆæ„å‘³ç€ä¹‹å‰å¤„ç†è¿‡æ–‡ä»¶ï¼‰
        st.info("æœªä¸Šä¼ æ–°çš„æ–‡æ¡£ï¼Œä½†æ£€æµ‹åˆ°ä¹‹å‰å·²å¤„ç†çš„æ–‡æ¡£æ•°æ®ã€‚æ­£åœ¨å°è¯•åŠ è½½...")
        needs_rebuild = False # å°è¯•åŠ è½½æ—§æ•°æ®
    else: # æ—¢æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶ï¼Œä¹Ÿæ²¡æœ‰æ—§çŠ¶æ€
        st.warning("æ²¡æœ‰ä¸Šä¼ æ–°çš„æ–‡æ¡£ï¼Œä¹Ÿæœªæ‰¾åˆ°ä¹‹å‰çš„æ–‡æ¡£æ•°æ®ã€‚è¯·ä¸Šä¼  PDF æ–‡æ¡£ä»¥å¼€å§‹ã€‚")
        return None, False # æ— æ³•ç»§ç»­ï¼Œè¿”å› Noneå’ŒFalse

    # 3. æ ¹æ®åˆ¤æ–­ç»“æœæ‰§è¡ŒåŠ è½½æˆ–é‡å»º
    if needs_rebuild:
        # æ¸…é™¤æ—§çš„ ChromaDB ç›®å½•å’ŒçŠ¶æ€æ–‡ä»¶
        if os.path.exists(PERSIST_DIRECTORY):
            st.info(f"æ­£åœ¨æ¸…ç†æ—§çš„ Chroma ç›®å½•: {PERSIST_DIRECTORY}")
            try:
                shutil.rmtree(PERSIST_DIRECTORY)
                st.success("æ—§çš„ Chroma ç›®å½•å·²æ¸…ç†ã€‚")
            except Exception as cleanup_e:
                st.error(f"æ¸…ç†æ—§çš„ Chroma ç›®å½•å¤±è´¥: {cleanup_e}")
                logging.error(f"æ¸…ç†æ—§çš„ Chroma ç›®å½•å¤±è´¥: {cleanup_e}", exc_info=True)

        # å¤„ç†ä¸Šä¼ æ–‡ä»¶å¹¶åˆ›å»ºæ–°çš„ ChromaDB
        docs = []
        temp_dir = None
        all_splits = []

        try:
            # 3.1. å¤„ç†ä¸Šä¼ æ–‡ä»¶ç”¨äº Chroma
            temp_dir = tempfile.TemporaryDirectory()
            st.info(f"å¼€å§‹å¤„ç† {len(uploaded_files)} ä¸ªä¸Šä¼ çš„æ–‡ä»¶ (ç”¨äº Chroma)...")

            for file in uploaded_files:
                # æ³¨æ„ï¼šcalculate_file_hash å·²ç»æŠŠæ–‡ä»¶æŒ‡é’ˆé‡ç½®äº†
                temp_filepath = os.path.join(temp_dir.name, file.name)
                try:
                    # å†æ¬¡ç¡®ä¿æ–‡ä»¶æŒ‡é’ˆåœ¨å¼€å§‹ï¼Œè™½ç„¶calculate_file_hashå·²åšï¼Œè¿™é‡Œæ˜¯åŒé‡ä¿é™©
                    file.seek(0)
                    with open(temp_filepath, "wb") as f:
                        f.write(file.getvalue())
                    loader = PyPDFLoader(temp_filepath)
                    file_docs = loader.load()
                    if not file_docs:
                         logging.warning(f"æ–‡ä»¶ {file.name} åŠ è½½åæœªäº§ç”Ÿæ–‡æ¡£ã€‚")
                         continue
                    # ä½¿ç”¨ä¹‹å‰è°ƒè¯•ç¡®è®¤çš„è¾ƒä¼˜å‚æ•°
                    text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=100)
                    splits = text_splitter.split_documents(file_docs)
                    all_splits.extend(splits)
                    logging.info(f"æˆåŠŸåŠ è½½å¹¶åˆ†å‰²äº† {file.name}ï¼Œäº§ç”Ÿ {len(splits)} ä¸ªç‰‡æ®µã€‚")
                except Exception as e:
                    st.error(f"åŠ è½½æˆ–å¤„ç† PDF æ–‡ä»¶ {file.name} æ—¶å‡ºé”™: {e}")
                    logging.error(f"å¤„ç† {file.name} æ—¶å‡ºé”™: {e}", exc_info=True)

            if not all_splits:
                st.warning("æ²¡æœ‰æˆåŠŸåŠ è½½æˆ–åˆ†å‰²ä»»ä½•ä¸Šä¼ çš„æ–‡æ¡£ç”¨äº Chromaã€‚")
                return None, False # æ²¡æœ‰æ–‡æ¡£å¤„ç†æˆåŠŸï¼Œæ— æ³•åˆ›å»ºå‘é‡åº“

            # 3.2. åˆ›å»º Chroma å‘é‡å­˜å‚¨å¹¶æŒä¹…åŒ–
            try:
                st.info(f"æ­£åœ¨åˆ›å»º Chroma å‘é‡å­˜å‚¨å¹¶æŒä¹…åŒ–åˆ° {PERSIST_DIRECTORY} (å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´)...")
                # from_documents ä¼šåœ¨æŒ‡å®šçš„ persist_directory åˆ›å»ºå¹¶ä¿å­˜æ•°æ®åº“
                vectordb = Chroma.from_documents(
                    all_splits,
                    embeddings, # <--- ä¼ å…¥å‰é¢åˆ›å»ºçš„embeddingså®ä¾‹
                    persist_directory=PERSIST_DIRECTORY
                )
                st.success(f"æ–°çš„ Chroma å‘é‡å­˜å‚¨åˆ›å»ºæˆåŠŸå¹¶å·²æŒä¹…åŒ–åˆ° {PERSIST_DIRECTORY}ã€‚")

                # ä¿å­˜å½“å‰æ–‡ä»¶çŠ¶æ€
                save_processed_state(current_files_state)
                st.success("å·²ä¿å­˜å½“å‰æ–‡ä»¶çŠ¶æ€ã€‚")

                # è·å–æ£€ç´¢å™¨
                chroma_retriever = vectordb.as_retriever(
                    search_type="sim",
                    search_kwargs={"k": 16}
                )
                st.success("Chroma æ£€ç´¢å™¨é…ç½®æˆåŠŸã€‚")
                return chroma_retriever, False # æˆåŠŸåˆ›å»ºå¹¶æŒä¹…åŒ–åè¿”å›æ£€ç´¢å™¨å’ŒFalse

            except Exception as e:
                st.error(f"åˆ›å»º Chroma å‘é‡å­˜å‚¨æˆ–æ£€ç´¢å™¨å¤±è´¥: {e}")
                logging.error("Chroma åˆ›å»ºå¤±è´¥:", exc_info=True)
                # æ·»åŠ æ˜¾å­˜ä¸è¶³çš„æç¤ºç­‰
                if "out of memory" in str(e).lower():
                     st.error("GPU æ˜¾å­˜ä¸è¶³ï¼è¯·å°è¯•å…³é—­å…¶ä»–å ç”¨æ˜¾å­˜çš„ç¨‹åºï¼Œæˆ–åœ¨ä»£ç ä¸­å°† device æ”¹ä¸º 'cpu'ã€‚")
                elif "meta tensor" in str(e):
                     st.error("åŠ è½½æ¨¡å‹æ—¶é‡åˆ° Meta Tensor é”™è¯¯ã€‚è¯·å°è¯•æ¸…ç† Hugging Face æ¨¡å‹ç¼“å­˜ï¼Œç„¶åé‡å¯åº”ç”¨ã€‚")
                else:
                    pass # st.error å·²åœ¨ä¸Šé¢æ˜¾ç¤ºäº†é€šç”¨é”™è¯¯
                return None, False # åˆ›å»ºå¤±è´¥åˆ™è¿”å› Noneå’ŒFalse

        except Exception as e:
            st.error(f"åœ¨æ£€ç´¢å™¨é…ç½®è¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
            logging.error("æ£€ç´¢å™¨é…ç½®å¤±è´¥:", exc_info=True)
            return None, False
        finally:
            if temp_dir:
                try:
                    temp_dir.cleanup()
                    logging.info("ä¸´æ—¶ç›®å½•å·²æ¸…ç†ã€‚")
                except Exception as e:
                    logging.warning(f"æ— æ³•æ¸…ç†ä¸´æ—¶ç›®å½•: {e}")

    else: # ä¸éœ€è¦é‡å»ºï¼Œå°è¯•ä»æŒä¹…åŒ–ç›®å½•åŠ è½½
        try:
            st.info(f"æ­£åœ¨å°è¯•ä»æŒä¹…åŒ–ç›®å½•åŠ è½½ Chroma å‘é‡å­˜å‚¨: {PERSIST_DIRECTORY}...")
            # Chroma ä¼šè‡ªåŠ¨åŠ è½½å¦‚æœæ•°æ®å­˜åœ¨
            # æ³¨æ„ï¼šè¿™é‡ŒåŠ è½½æ—¶ä¹Ÿéœ€è¦ embedding_function å‚æ•°
            vectordb = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings)
            st.success("æˆåŠŸåŠ è½½ç°æœ‰çš„ Chroma å‘é‡å­˜å‚¨ã€‚")
            chroma_retriever = vectordb.as_retriever(
                search_type="mmr",
                search_kwargs={"k": 16}
            )
            st.success("Chroma æ£€ç´¢å™¨åŠ è½½æˆåŠŸã€‚")
            was_loaded_from_disk = True # è®¾ç½®åŠ è½½æ ‡å¿—ä¸ºTrue
            return chroma_retriever, was_loaded_from_disk # æˆåŠŸåŠ è½½ï¼Œè¿”å›æ£€ç´¢å™¨å’ŒTrue

        except Exception as e:
            st.error(f"ä»æŒä¹…åŒ–ç›®å½•åŠ è½½ Chroma å¤±è´¥ ({e})ã€‚")
            logging.warning(f"Chroma åŠ è½½å¤±è´¥: {e}", exc_info=True)
            # åŠ è½½å¤±è´¥æ—¶ï¼Œå³ä½¿ä¹‹å‰åˆ¤æ–­ä¸éœ€è¦é‡å»ºï¼Œç°åœ¨ä¹Ÿæ— æ³•ä½¿ç”¨æ—§æ•°æ®
            st.warning("åŠ è½½ç°æœ‰æ•°æ®å¤±è´¥ï¼Œè¯·å°è¯•é‡æ–°ä¸Šä¼ æ–‡ä»¶æˆ–æ¸…é™¤ç¼“å­˜ã€‚")
            return None, False # åŠ è½½å¤±è´¥ï¼Œè¿”å› Noneå’ŒFalse


# --- Streamlit åº”ç”¨ä¸»é€»è¾‘ ---

# 1. æ–‡ä»¶ä¸Šä¼ 
uploaded_files = st.sidebar.file_uploader(
    label="ä¸Šä¼  PDF æ–‡ä»¶",
    type=["pdf"],
    accept_multiple_files=True,
    key="pdf_uploader_dashscope_chroma_cn_v2" # æ·»åŠ  key ç¡®ä¿å”¯ä¸€æ€§
)

# 2. é…ç½®æ£€ç´¢å™¨ (ä¼šæ£€æŸ¥æ–‡ä»¶å˜æ›´å¹¶å†³å®šåŠ è½½æˆ–åˆ›å»º)
with st.spinner("æ­£åœ¨å¤„ç†ä¸Šä¼ çš„æ–‡æ¡£æˆ–åŠ è½½ç°æœ‰çš„ Chroma æ£€ç´¢å™¨å¹¶æ£€æŸ¥æ–‡ä»¶å˜æ›´..."):
    # è°ƒç”¨å‡½æ•°å¹¶æ¥æ”¶ä¸¤ä¸ªè¿”å›å€¼
    retriever, loaded_from_disk = configure_retriever(uploaded_files)

# å¦‚æœæ£€ç´¢å™¨é…ç½®å¤±è´¥ï¼Œåœæ­¢åº”ç”¨
if retriever is None:
    st.error("æœªèƒ½é…ç½®æˆ–åŠ è½½ Chroma æ–‡æ¡£æ£€ç´¢å™¨ï¼Œæ— æ³•ç»§ç»­ã€‚è¯·æ£€æŸ¥ä¸Šä¼ çš„æ–‡ä»¶ã€é”™è¯¯æ—¥å¿—æˆ–å°è¯•æ¸…é™¤ç¼“å­˜ã€‚")
    st.stop()

# 3. åˆå§‹åŒ– LLM (è¿™éƒ¨åˆ†ä¸å—æ–‡ä»¶ä¸Šä¼ å’ŒæŒä¹…åŒ–å½±å“ï¼Œæ¯æ¬¡è¿è¡Œ Streamlit éƒ½ä¼šæ‰§è¡Œ)
try:
    st.info(f"æ­£åœ¨åˆå§‹åŒ– DashScope LLM: {MODEL_ID}...")
    llm = ChatOpenAI(
        model_name=MODEL_ID,
        openai_api_key=DASHSCOPE_API_KEY,
        openai_api_base=DASHSCOPE_API_BASE,
        temperature=0.5,
        max_tokens=1024,
    )
    st.success(f"DashScope LLM ({MODEL_ID}) åˆå§‹åŒ–æˆåŠŸã€‚")
except Exception as e:
    st.error(f"åˆå§‹åŒ– DashScope LLM ({MODEL_ID}) å¤±è´¥: {e}")
    logging.error("DashScope LLM åˆå§‹åŒ–å¤±è´¥:", exc_info=True)
    if "api_key" in str(e).lower() or "authenticate" in str(e).lower():
        st.error("è®¤è¯å¤±è´¥ã€‚è¯·æ£€æŸ¥ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY æ˜¯å¦å·²æ­£ç¡®è®¾ç½®ä¸” Key æœ¬èº«æœ‰æ•ˆã€‚")
    elif "base_url" in str(e).lower() or "connection" in str(e).lower():
         st.error(f"è¿æ¥å¤±è´¥ã€‚è¯·æ£€æŸ¥ Base URL ({DASHSCOPE_API_BASE}) æ˜¯å¦æ­£ç¡®ä»¥åŠç½‘ç»œè¿æ¥æ˜¯å¦èƒ½è®¿é—®è¯¥åœ°å€ã€‚")
    elif "model" in str(e).lower() or "not found" in str(e).lower():
         st.error(f"æ¨¡å‹é”™è¯¯ã€‚è¯·æ£€æŸ¥æ¨¡å‹åç§° '{MODEL_ID}' æ˜¯å¦æ˜¯ DashScope æ”¯æŒçš„æœ‰æ•ˆæ¨¡å‹ã€‚")
    else:
         st.error(f"è¯·æ£€æŸ¥ API Keyã€æ¨¡å‹åç§° ('{MODEL_ID}')ã€Base URL åŠç½‘ç»œè¿æ¥ã€‚")
    st.stop()


# 4. åˆå§‹åŒ–èŠå¤©è®°å½•
# ç¡®ä¿èŠå¤©è®°å½•çš„ key è¶³å¤Ÿç‹¬ç‰¹ï¼Œä»¥å…ä¸å…¶ä»–åº”ç”¨çš„èŠå¤©è®°å½•æ··åˆ
msgs = StreamlitChatMessageHistory(key="rag_chat_messages_dashscope_chroma_cn_v2_persistent")

# 5. å®šä¹‰ Prompt æ¨¡æ¿ (ä¿æŒä¸å˜)
RESPONSE_TEMPLATE = """<s>[INST]
<<SYS>>
Your Promptï¼Please use a specific prompt for getting a precise resultï¼
<<SYS>>

ä»æ‰€æä¾›çš„XXXæ–‡æ¡£ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³ä¸Šä¸‹æ–‡ä¿¡æ¯:
---
{context}
---

ç”¨æˆ·é—®é¢˜: {question}
[/INST]
XXXåŠ©æ‰‹å›ç­”:
"""

PROMPT = PromptTemplate(template=RESPONSE_TEMPLATE, input_variables=["context", "question"])


# 6. åˆ›å»º RAG é—®ç­”é“¾
try:
    st.info("æ­£åœ¨åˆ›å»º RAG é—®ç­”é“¾ (ä½¿ç”¨ ChromaDB å’Œ DashScope LLM)...")
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type='stuff',
        retriever=retriever,
        chain_type_kwargs={"prompt": PROMPT},
        return_source_documents=True
    )
    st.success("RAG é—®ç­”é“¾å‡†å¤‡å°±ç»ªã€‚")
except Exception as e:
    st.error(f"åˆ›å»º RAG QA é“¾å¤±è´¥: {e}")
    logging.error("RAG é“¾åˆ›å»ºå¤±è´¥:", exc_info=True)
    st.stop()

# 7. æ˜¾ç¤ºèŠå¤©ç•Œé¢å’Œå¤„ç†ç”¨æˆ·è¾“å…¥

# æ ¹æ®æ˜¯å¦æ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œæˆ–ç‚¹å‡»äº†â€œæ–°å¯¹è¯â€ï¼Œä»¥åŠæ•°æ®æ˜¯å¦åŠ è½½è‡ªç£ç›˜æ¥æ˜¾ç¤ºåˆå§‹æ¶ˆæ¯
if len(msgs.messages) == 0 or st.sidebar.button("å¼€å§‹æ–°å¯¹è¯", key="new_chat_button_dashscope_chroma_cn_v2_persistent"):
    msgs.clear()
    # ä½¿ç”¨ä»configure_retrieverè¿”å›çš„loaded_from_diskæ ‡å¿—
    if loaded_from_disk:
         initial_message = f"å·²åŠ è½½ä¹‹å‰çš„æ–‡æ¡£æ•°æ®ã€‚å…³äºè¿™äº›æ–‡æ¡£ï¼ˆä½¿ç”¨ ChromaDB æ£€ç´¢å’Œ DashScope LLMï¼‰ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ"
    elif uploaded_files: # å¦‚æœæœ‰ä¸Šä¼ æ–‡ä»¶ä¸”ä¸æ˜¯åŠ è½½çš„ï¼Œé‚£å°±æ˜¯æ–°å»ºæˆ–é‡å»ºäº†
         initial_message = f"å·²å¤„ç†æ‚¨ä¸Šä¼ çš„æ–‡æ¡£å¹¶åˆ›å»ºç´¢å¼•ã€‚å…³äºè¿™äº›æ–‡æ¡£ï¼ˆä½¿ç”¨ ChromaDB æ£€ç´¢å’Œ DashScope LLMï¼‰ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ"
    else: # æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶ï¼Œä¹Ÿæ²¡æœ‰åŠ è½½æ—§æ•°æ® (ç†è®ºä¸Šå‰é¢åº”è¯¥stopäº†ï¼Œè¿™é‡Œä½œä¸ºå®‰å…¨ç½‘)
         initial_message = "è¯·ä¸Šä¼  PDF æ–‡æ¡£ä»¥å¼€å§‹å¯¹è¯ã€‚"

    msgs.add_ai_message(initial_message)


# ä½¿ç”¨ Emojis ä½œä¸ºå¤´åƒ
avatars = {"human": "ğŸ§‘â€ğŸ’»", "ai": "ğŸ¤–"}

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in msgs.messages:
    st.chat_message(msg.type, avatar=avatars.get(msg.type)).write(msg.content)

# å¤„ç†ç”¨æˆ·è¾“å…¥
if user_query := st.chat_input(placeholder="å°±æ‚¨çš„æ–‡æ¡£æå‡ºé—®é¢˜...", key="user_query_input_dashscope_chroma_cn_v2_persistent"):
    msgs.add_user_message(user_query)
    st.chat_message("human", avatar=avatars["human"]).write(user_query)

    with st.chat_message("ai", avatar=avatars["ai"]):
        placeholder = st.empty()
        placeholder.markdown("æ€è€ƒä¸­ (æ­£åœ¨ä½¿ç”¨ ChromaDB æ£€ç´¢å’Œ DashScope LLM)...")
        try:
            # è°ƒç”¨ QA é“¾
            response = qa_chain.invoke({"query": user_query})
            answer = response.get("result")

            if answer is None:
                 answer = "æŠ±æ­‰ï¼Œæœªèƒ½ç”Ÿæˆå›ç­”ã€‚è¯·å°è¯•é‡æ–°æé—®æˆ–æ£€æŸ¥æ¨¡å‹çŠ¶æ€ã€‚"
                 logging.error(f"QA chain for query '{user_query}' returned None result. Response: {response}")

            placeholder.empty()
            st.markdown(answer)
            msgs.add_ai_message(answer)

            # --- > æ·»åŠ æ˜¾ç¤ºä¸Šä¸‹æ–‡çš„è°ƒè¯•ä»£ç ï¼ˆä¿æŒï¼Œç”¨äºéªŒè¯æ£€ç´¢æ•ˆæœï¼‰ <---
            retrieved_docs = response.get("source_documents", [])
            if retrieved_docs:
                with st.expander("æŸ¥çœ‹æœ¬æ¬¡æŸ¥è¯¢æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ¥æº", expanded=False): # é»˜è®¤æŠ˜å 
                     for i, doc in enumerate(retrieved_docs):
                        source = doc.metadata.get('source', 'æœªçŸ¥æ¥æº')
                        page = doc.metadata.get('page', '?')
                        if isinstance(page, int):
                             page += 1 # PDF é¡µç ä» 1 å¼€å§‹
                        st.write(f"**ä¸Šä¸‹æ–‡å— {i+1}:** (æ¥æº: {source}, é¡µç : {page})")
                        # æ˜¾ç¤ºéƒ¨åˆ†å†…å®¹å³å¯ï¼Œé¿å…è¿‡é•¿
                        st.caption(doc.page_content[:800] + "..." if len(doc.page_content) > 800 else doc.page_content)
                        st.write("---")
            else:
                logging.warning("é—®ç­”é“¾æ²¡æœ‰è¿”å›æºæ–‡æ¡£ä¿¡æ¯ã€‚")
            # --- > è°ƒè¯•ä»£ç ç»“æŸ <---


        except Exception as e:
            placeholder.empty()
            error_msg = f"å¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}"
            st.error(error_msg)
            logging.error(f"å¤„ç†æŸ¥è¯¢ '{user_query}' æ—¶å‡ºé”™:", exc_info=True)
            if "api_key" in str(e).lower() or "authenticate" in str(e).lower():
                 msgs.add_ai_message("æŠ±æ­‰ï¼Œå°è¯•å›ç­”æ‚¨çš„é—®é¢˜æ—¶é‡åˆ°äº† API å¯†é’¥è®¤è¯é”™è¯¯ã€‚è¯·è”ç³»ç®¡ç†å‘˜æ£€æŸ¥é…ç½®ã€‚")
            elif "rate limit" in str(e).lower():
                 msgs.add_ai_message("æŠ±æ­‰ï¼Œè¾¾åˆ°äº† API è°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œè¯·ç¨åå†è¯•ã€‚")
            elif "connection" in str(e).lower():
                  msgs.add_ai_message("æŠ±æ­‰ï¼Œå°è¯•è¿æ¥ DashScope API æ—¶å‡ºé”™ï¼Œè¯·æ£€æŸ¥ç½‘ç»œã€‚")
            else:
                 msgs.add_ai_message(f"æŠ±æ­‰ï¼Œå°è¯•å›ç­”æ‚¨çš„é—®é¢˜æ—¶é‡åˆ°äº†å†…éƒ¨é”™è¯¯ã€‚é”™è¯¯è¯¦æƒ…: {str(e)[:100]}...")


# --- ä¾§è¾¹æ  "å…³äº" éƒ¨åˆ† ---
about = st.sidebar.expander("å…³äºæ­¤åº”ç”¨")
# åœ¨å…³äºéƒ¨åˆ†åŠ¨æ€æ˜¾ç¤ºæ˜¯å¦åŠ è½½äº†æŒä¹…åŒ–æ•°æ®
persistence_status = f'æŒä¹…åŒ–åˆ°ç›®å½• `{PERSIST_DIRECTORY}`'
if retriever is not None: # åªæœ‰åœ¨æ£€ç´¢å™¨æˆåŠŸé…ç½®åæ‰æ˜¾ç¤ºçŠ¶æ€
    if loaded_from_disk:
         persistence_status += " (å·²åŠ è½½ç°æœ‰æ•°æ®)"
    elif uploaded_files:
         persistence_status += " (å·²æ ¹æ®ä¸Šä¼ æ–‡ä»¶åˆ›å»º/æ›´æ–°)"
    else: # retriever is not None but not loaded_from_disk and no uploaded files - this case should ideally not happen if retriever is not None
         persistence_status += " (å·²å°±ç»ªï¼Œæ— æ–‡ä»¶ä¸Šä¼ )"
else:
     persistence_status = "æŒä¹…åŒ–çŠ¶æ€æœªçŸ¥ (æ£€ç´¢å™¨é…ç½®å¤±è´¥)"


about.write(f"""
    è¿™æ˜¯ä¸€ä¸ªåŸºäº RAG (Retrieval-Augmented Generation) çš„ AI åŠ©æ‰‹ï¼Œå¯ä»¥ä¸æ‚¨ä¸Šä¼ çš„ PDF æ–‡æ¡£è¿›è¡Œå¯¹è¯ã€‚

    **å…³é”®ç‰¹æ€§:**
    *   æ”¯æŒä¸Šä¼  PDF æ–‡æ¡£ã€‚
    *   ä½¿ç”¨ BGE åµŒå…¥æ¨¡å‹å°†æ–‡æ¡£å†…å®¹è½¬æ¢ä¸ºå‘é‡ã€‚
    *   ä½¿ç”¨ ChromaDB å­˜å‚¨å’Œæ£€ç´¢æ–‡æ¡£å‘é‡ï¼ˆ**æ”¯æŒæŒä¹…åŒ–ä¸æ–‡ä»¶åŒæ­¥**ï¼‰ã€‚
    *   åˆ©ç”¨ DashScope çš„ {MODEL_ID} æ¨¡å‹æ ¹æ®æ£€ç´¢åˆ°çš„ä¿¡æ¯ç”Ÿæˆå›ç­”ã€‚

    **æŠ€æœ¯æ ˆ:**
    *   **è¯­è¨€æ¨¡å‹:** {MODEL_ID} (é€šè¿‡é˜¿é‡Œäº‘ DashScope)
    *   **åµŒå…¥æ¨¡å‹:** BAAI BGE (langchain-huggingface, åœ¨ {'GPU' if torch.cuda.is_available() else 'CPU'} ä¸Šè¿è¡Œ) # <-- åŠ¨æ€æ˜¾ç¤ºè®¾å¤‡
    *   **æ£€ç´¢å™¨ & å‘é‡åº“:** ChromaDB ({persistence_status})
    *   **æ¡†æ¶:** Langchain & Streamlit

    **æ–‡ä»¶åŒæ­¥è¯´æ˜:**
    åº”ç”¨ä¼šè®¡ç®—ä¸Šä¼ æ–‡ä»¶çš„å†…å®¹å“ˆå¸Œå€¼ï¼Œå¹¶ä¸ä¹‹å‰ä¿å­˜çš„çŠ¶æ€è¿›è¡Œæ¯”å¯¹ã€‚å¦‚æœæ£€æµ‹åˆ°æ‚¨æœ¬æ¬¡ä¸Šä¼ çš„æ–‡ä»¶é›†åˆä¸ä¹‹å‰å¤„ç†çš„ä¸åŒï¼ˆåŒ…æ‹¬æ–‡ä»¶çš„æ·»åŠ ã€åˆ é™¤æˆ–å†…å®¹ä¿®æ”¹ï¼‰ï¼Œå°†è‡ªåŠ¨æ¸…é™¤æ—§æ•°æ®ï¼Œå¹¶æ ¹æ®å½“å‰ä¸Šä¼ çš„æ‰€æœ‰æ–‡ä»¶é‡æ–°åˆ›å»ºå‘é‡æ•°æ®åº“ï¼Œä»¥ç¡®ä¿æ£€ç´¢çš„å‡†ç¡®æ€§ã€‚å¦‚æœä¸Šä¼ æ–‡ä»¶ä¸ä¹‹å‰ä¸€è‡´ï¼Œåˆ™å¿«é€ŸåŠ è½½å·²ä¿å­˜çš„æ•°æ®ã€‚
""")
